{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 64,
   "id": "96c03c1d",
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "import pandas as pd\n",
    "import pymongo\n",
    "from pymongo import MongoClient\n",
    "cluster=MongoClient()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "id": "f8846017",
   "metadata": {},
   "outputs": [],
   "source": [
    "db=cluster[\"project\"]\n",
    "collection=db[\"data\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "id": "15482a35",
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(\"walking.json\", \"r\") as read_file:\n",
    "        data = json.load(read_file)\n",
    "prop=[\"accelerometer\",\"gyroscope\"]\n",
    "a=json.loads(data[0][\"accelerometer\"])\n",
    "acc_x=[]\n",
    "acc_y=[]\n",
    "acc_z=[]\n",
    "gyr_x=[]\n",
    "gyr_y=[]\n",
    "gyr_z=[]\n",
    "lab=[]\n",
    "\n",
    "for i in data:\n",
    "    temp=json.loads(i[\"accelerometer\"]) \n",
    "    temp2=json.loads(i[\"gyroscope\"])\n",
    "    a1=temp[0]\n",
    "    a2=temp[1]\n",
    "    a3=temp[2]\n",
    "    b1=temp2[0]\n",
    "    b2=temp2[1]\n",
    "    b3=temp2[2]\n",
    "    \n",
    "    acc_x.append(a1)\n",
    "    acc_y.append(a2)\n",
    "    acc_z.append(a3)\n",
    "    gyr_x.append(b1)\n",
    "    gyr_y.append(b2)\n",
    "    gyr_z.append(b3)\n",
    "    lab.append(1)\n",
    "    dict1={\"acc_x\":a1,\"acc_y\":a2,\"acc_z\":a3,\"gyr_x\":b1,\"gyr_y\":b2,\"gyr_z\":b3,\"Lable\":1}\n",
    "    collection.insert_one(dict1)\n",
    "    dict1.clear()\n",
    "    \n",
    "df1 = pd.DataFrame(list(zip(acc_x,acc_y,acc_z, gyr_x,gyr_y,gyr_z,lab)), columns =[\"acc_x\",\"acc_y\",\"acc_z\", \"gyr_x\",\"gyr_y\",\"gyr_z\",\"lable\"])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "adfe9e04",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "id": "06e47ea6",
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(\"standing.json\", \"r\") as read_file:\n",
    "        data = json.load(read_file)\n",
    "prop=[\"accelerometer\",\"gyroscope\"]\n",
    "a=json.loads(data[0][\"accelerometer\"])\n",
    "acc_x=[]\n",
    "acc_y=[]\n",
    "acc_z=[]\n",
    "gyr_x=[]\n",
    "gyr_y=[]\n",
    "gyr_z=[]\n",
    "lab=[]\n",
    "\n",
    "for i in data:\n",
    "    temp=json.loads(i[\"accelerometer\"]) \n",
    "    temp2=json.loads(i[\"gyroscope\"])\n",
    "    a1=temp[0]\n",
    "    a2=temp[1]\n",
    "    a3=temp[2]\n",
    "    b1=temp2[0]\n",
    "    b2=temp2[1]\n",
    "    b3=temp2[2]\n",
    "    \n",
    "    acc_x.append(a1)\n",
    "    acc_y.append(a2)\n",
    "    acc_z.append(a3)\n",
    "    gyr_x.append(b1)\n",
    "    gyr_y.append(b2)\n",
    "    gyr_z.append(b3)\n",
    "    lab.append(2)\n",
    "    dict1={\"acc_x\":a1,\"acc_y\":a2,\"acc_z\":a3,\"gyr_x\":b1,\"gyr_y\":b2,\"gyr_z\":b3,\"Lable\":2}\n",
    "    collection.insert_one(dict1)\n",
    "    dict1.clear()\n",
    "df2 = pd.DataFrame(list(zip(acc_x,acc_y,acc_z, gyr_x,gyr_y,gyr_z,lab)), columns =[\"acc_x\",\"acc_y\",\"acc_z\", \"gyr_x\",\"gyr_y\",\"gyr_z\",\"lable\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "id": "39a7aa53",
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(\"running.json\", \"r\") as read_file:\n",
    "        data = json.load(read_file)\n",
    "prop=[\"accelerometer\",\"gyroscope\"]\n",
    "a=json.loads(data[0][\"accelerometer\"])\n",
    "acc_x=[]\n",
    "acc_y=[]\n",
    "acc_z=[]\n",
    "gyr_x=[]\n",
    "gyr_y=[]\n",
    "gyr_z=[]\n",
    "lab=[]\n",
    "\n",
    "for i in data:\n",
    "    temp=json.loads(i[\"accelerometer\"]) \n",
    "    temp2=json.loads(i[\"gyroscope\"])\n",
    "    a1=temp[0]\n",
    "    a2=temp[1]\n",
    "    a3=temp[2]\n",
    "    b1=temp2[0]\n",
    "    b2=temp2[1]\n",
    "    b3=temp2[2]\n",
    "    \n",
    "    acc_x.append(a1)\n",
    "    acc_y.append(a2)\n",
    "    acc_z.append(a3)\n",
    "    gyr_x.append(b1)\n",
    "    gyr_y.append(b2)\n",
    "    gyr_z.append(b3)\n",
    "    lab.append(3)\n",
    "    dict1={\"acc_x\":a1,\"acc_y\":a2,\"acc_z\":a3,\"gyr_x\":b1,\"gyr_y\":b2,\"gyr_z\":b3,\"Lable\":3}\n",
    "    collection.insert_one(dict1)\n",
    "    dict1.clear()\n",
    "df3 = pd.DataFrame(list(zip(acc_x,acc_y,acc_z, gyr_x,gyr_y,gyr_z,lab)), columns =[\"acc_x\",\"acc_y\",\"acc_z\", \"gyr_x\",\"gyr_y\",\"gyr_z\",\"lable\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "id": "8b7aa302",
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(\"PhoneInUse.json\", \"r\") as read_file:\n",
    "        data = json.load(read_file)\n",
    "prop=[\"accelerometer\",\"gyroscope\"]\n",
    "a=json.loads(data[0][\"accelerometer\"])\n",
    "acc_x=[]\n",
    "acc_y=[]\n",
    "acc_z=[]\n",
    "gyr_x=[]\n",
    "gyr_y=[]\n",
    "gyr_z=[]\n",
    "lab=[]\n",
    "\n",
    "for i in data:\n",
    "    temp=json.loads(i[\"accelerometer\"]) \n",
    "    temp2=json.loads(i[\"gyroscope\"])\n",
    "    a1=temp[0]\n",
    "    a2=temp[1]\n",
    "    a3=temp[2]\n",
    "    b1=temp2[0]\n",
    "    b2=temp2[1]\n",
    "    b3=temp2[2]\n",
    "    \n",
    "    acc_x.append(a1)\n",
    "    acc_y.append(a2)\n",
    "    acc_z.append(a3)\n",
    "    gyr_x.append(b1)\n",
    "    gyr_y.append(b2)\n",
    "    gyr_z.append(b3)\n",
    "    lab.append(4)\n",
    "    dict1={\"acc_x\":a1,\"acc_y\":a2,\"acc_z\":a3,\"gyr_x\":b1,\"gyr_y\":b2,\"gyr_z\":b3,\"Lable\":4}\n",
    "    collection.insert_one(dict1)\n",
    "    dict1.clear()\n",
    "df4 = pd.DataFrame(list(zip(acc_x,acc_y,acc_z, gyr_x,gyr_y,gyr_z,lab)), columns =[\"acc_x\",\"acc_y\",\"acc_z\", \"gyr_x\",\"gyr_y\",\"gyr_z\",\"lable\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "id": "64fb2d2f",
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(\"Not_in_use.json\", \"r\") as read_file:\n",
    "        data = json.load(read_file)\n",
    "prop=[\"accelerometer\",\"gyroscope\"]\n",
    "a=json.loads(data[0][\"accelerometer\"])\n",
    "acc_x=[]\n",
    "acc_y=[]\n",
    "acc_z=[]\n",
    "gyr_x=[]\n",
    "gyr_y=[]\n",
    "gyr_z=[]\n",
    "lab=[]\n",
    "\n",
    "for i in data:\n",
    "    temp=json.loads(i[\"accelerometer\"]) \n",
    "    temp2=json.loads(i[\"gyroscope\"])\n",
    "    a1=temp[0]\n",
    "    a2=temp[1]\n",
    "    a3=temp[2]\n",
    "    b1=temp2[0]\n",
    "    b2=temp2[1]\n",
    "    b3=temp2[2]\n",
    "    \n",
    "    acc_x.append(a1)\n",
    "    acc_y.append(a2)\n",
    "    acc_z.append(a3)\n",
    "    gyr_x.append(b1)\n",
    "    gyr_y.append(b2)\n",
    "    gyr_z.append(b3)\n",
    "    lab.append(5)\n",
    "    dict1={\"acc_x\":a1,\"acc_y\":a2,\"acc_z\":a3,\"gyr_x\":b1,\"gyr_y\":b2,\"gyr_z\":b3,\"Lable\":5}\n",
    "    collection.insert_one(dict1)\n",
    "    dict1.clear()\n",
    "df5 = pd.DataFrame(list(zip(acc_x,acc_y,acc_z, gyr_x,gyr_y,gyr_z,lab)), columns =[\"acc_x\",\"acc_y\",\"acc_z\", \"gyr_x\",\"gyr_y\",\"gyr_z\",\"lable\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e3202e81",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "id": "635d6d96",
   "metadata": {},
   "outputs": [],
   "source": [
    "finaldf=df1.append(df2)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "id": "d30c4755",
   "metadata": {},
   "outputs": [],
   "source": [
    "finaldf=finaldf.append(df3)\n",
    "finaldf=finaldf.append(df4)\n",
    "finaldf=finaldf.append(df5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "id": "3979930e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>acc_x</th>\n",
       "      <th>acc_y</th>\n",
       "      <th>acc_z</th>\n",
       "      <th>gyr_x</th>\n",
       "      <th>gyr_y</th>\n",
       "      <th>gyr_z</th>\n",
       "      <th>lable</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.838684</td>\n",
       "      <td>-0.408691</td>\n",
       "      <td>9.202316</td>\n",
       "      <td>0.301426</td>\n",
       "      <td>-0.089384</td>\n",
       "      <td>0.159393</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.838684</td>\n",
       "      <td>-0.408691</td>\n",
       "      <td>9.202316</td>\n",
       "      <td>0.309797</td>\n",
       "      <td>-0.095042</td>\n",
       "      <td>0.168932</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.838684</td>\n",
       "      <td>-0.408691</td>\n",
       "      <td>9.202316</td>\n",
       "      <td>0.288336</td>\n",
       "      <td>-0.082707</td>\n",
       "      <td>0.148026</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.838684</td>\n",
       "      <td>-0.408691</td>\n",
       "      <td>9.202316</td>\n",
       "      <td>0.273329</td>\n",
       "      <td>-0.075406</td>\n",
       "      <td>0.137241</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.838684</td>\n",
       "      <td>-0.408691</td>\n",
       "      <td>9.202316</td>\n",
       "      <td>0.258386</td>\n",
       "      <td>-0.069050</td>\n",
       "      <td>0.131529</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>802</th>\n",
       "      <td>-0.048455</td>\n",
       "      <td>0.158524</td>\n",
       "      <td>9.720243</td>\n",
       "      <td>0.001069</td>\n",
       "      <td>0.000916</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>803</th>\n",
       "      <td>-0.043669</td>\n",
       "      <td>0.153739</td>\n",
       "      <td>9.708280</td>\n",
       "      <td>0.001069</td>\n",
       "      <td>0.000916</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>804</th>\n",
       "      <td>-0.058026</td>\n",
       "      <td>0.170489</td>\n",
       "      <td>9.713065</td>\n",
       "      <td>0.001069</td>\n",
       "      <td>0.000916</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>805</th>\n",
       "      <td>-0.060419</td>\n",
       "      <td>0.156132</td>\n",
       "      <td>9.715458</td>\n",
       "      <td>0.001222</td>\n",
       "      <td>0.001374</td>\n",
       "      <td>0.000305</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>806</th>\n",
       "      <td>-0.048455</td>\n",
       "      <td>0.146560</td>\n",
       "      <td>9.722636</td>\n",
       "      <td>0.001222</td>\n",
       "      <td>0.000916</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>10480 rows × 7 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "        acc_x     acc_y     acc_z     gyr_x     gyr_y     gyr_z  lable\n",
       "0    0.838684 -0.408691  9.202316  0.301426 -0.089384  0.159393      1\n",
       "1    0.838684 -0.408691  9.202316  0.309797 -0.095042  0.168932      1\n",
       "2    0.838684 -0.408691  9.202316  0.288336 -0.082707  0.148026      1\n",
       "3    0.838684 -0.408691  9.202316  0.273329 -0.075406  0.137241      1\n",
       "4    0.838684 -0.408691  9.202316  0.258386 -0.069050  0.131529      1\n",
       "..        ...       ...       ...       ...       ...       ...    ...\n",
       "802 -0.048455  0.158524  9.720243  0.001069  0.000916  0.000000      5\n",
       "803 -0.043669  0.153739  9.708280  0.001069  0.000916  0.000000      5\n",
       "804 -0.058026  0.170489  9.713065  0.001069  0.000916  0.000000      5\n",
       "805 -0.060419  0.156132  9.715458  0.001222  0.001374  0.000305      5\n",
       "806 -0.048455  0.146560  9.722636  0.001222  0.000916  0.000000      5\n",
       "\n",
       "[10480 rows x 7 columns]"
      ]
     },
     "execution_count": 73,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "finaldf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "58d1d200",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "09c01914",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "id": "5877bb48",
   "metadata": {},
   "outputs": [],
   "source": [
    "#load data from mongodb directly \n",
    "import pymongo\n",
    "import pandas as pd\n",
    "from pymongo import MongoClient\n",
    "client = MongoClient()\n",
    "db = client.project\n",
    "collection = db.data\n",
    "bhbhb = pd.DataFrame(list(collection.find()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "id": "8293d59e",
   "metadata": {},
   "outputs": [],
   "source": [
    "bhbhb.drop([ '_id'], axis = 1, inplace = True) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "id": "7643221a",
   "metadata": {},
   "outputs": [],
   "source": [
    "finaldf=bhbhb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "id": "d6b08186",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>acc_x</th>\n",
       "      <th>acc_y</th>\n",
       "      <th>acc_z</th>\n",
       "      <th>gyr_x</th>\n",
       "      <th>gyr_y</th>\n",
       "      <th>gyr_z</th>\n",
       "      <th>Lable</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.838684</td>\n",
       "      <td>-0.408691</td>\n",
       "      <td>9.202316</td>\n",
       "      <td>0.301426</td>\n",
       "      <td>-0.089384</td>\n",
       "      <td>0.159393</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.838684</td>\n",
       "      <td>-0.408691</td>\n",
       "      <td>9.202316</td>\n",
       "      <td>0.309797</td>\n",
       "      <td>-0.095042</td>\n",
       "      <td>0.168932</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.838684</td>\n",
       "      <td>-0.408691</td>\n",
       "      <td>9.202316</td>\n",
       "      <td>0.288336</td>\n",
       "      <td>-0.082707</td>\n",
       "      <td>0.148026</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.838684</td>\n",
       "      <td>-0.408691</td>\n",
       "      <td>9.202316</td>\n",
       "      <td>0.273329</td>\n",
       "      <td>-0.075406</td>\n",
       "      <td>0.137241</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.838684</td>\n",
       "      <td>-0.408691</td>\n",
       "      <td>9.202316</td>\n",
       "      <td>0.258386</td>\n",
       "      <td>-0.069050</td>\n",
       "      <td>0.131529</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10475</th>\n",
       "      <td>-0.048455</td>\n",
       "      <td>0.158524</td>\n",
       "      <td>9.720243</td>\n",
       "      <td>0.001069</td>\n",
       "      <td>0.000916</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10476</th>\n",
       "      <td>-0.043669</td>\n",
       "      <td>0.153739</td>\n",
       "      <td>9.708280</td>\n",
       "      <td>0.001069</td>\n",
       "      <td>0.000916</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10477</th>\n",
       "      <td>-0.058026</td>\n",
       "      <td>0.170489</td>\n",
       "      <td>9.713065</td>\n",
       "      <td>0.001069</td>\n",
       "      <td>0.000916</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10478</th>\n",
       "      <td>-0.060419</td>\n",
       "      <td>0.156132</td>\n",
       "      <td>9.715458</td>\n",
       "      <td>0.001222</td>\n",
       "      <td>0.001374</td>\n",
       "      <td>0.000305</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10479</th>\n",
       "      <td>-0.048455</td>\n",
       "      <td>0.146560</td>\n",
       "      <td>9.722636</td>\n",
       "      <td>0.001222</td>\n",
       "      <td>0.000916</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>10480 rows × 7 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "          acc_x     acc_y     acc_z     gyr_x     gyr_y     gyr_z  Lable\n",
       "0      0.838684 -0.408691  9.202316  0.301426 -0.089384  0.159393      1\n",
       "1      0.838684 -0.408691  9.202316  0.309797 -0.095042  0.168932      1\n",
       "2      0.838684 -0.408691  9.202316  0.288336 -0.082707  0.148026      1\n",
       "3      0.838684 -0.408691  9.202316  0.273329 -0.075406  0.137241      1\n",
       "4      0.838684 -0.408691  9.202316  0.258386 -0.069050  0.131529      1\n",
       "...         ...       ...       ...       ...       ...       ...    ...\n",
       "10475 -0.048455  0.158524  9.720243  0.001069  0.000916  0.000000      5\n",
       "10476 -0.043669  0.153739  9.708280  0.001069  0.000916  0.000000      5\n",
       "10477 -0.058026  0.170489  9.713065  0.001069  0.000916  0.000000      5\n",
       "10478 -0.060419  0.156132  9.715458  0.001222  0.001374  0.000305      5\n",
       "10479 -0.048455  0.146560  9.722636  0.001222  0.000916  0.000000      5\n",
       "\n",
       "[10480 rows x 7 columns]"
      ]
     },
     "execution_count": 77,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "finaldf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "id": "14b076e7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Shape of X =  (10480, 6)\n",
      "Shape of y =  (10480,)\n"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "X = finaldf.drop(\"Lable\", axis = 1)\n",
    "y = finaldf[\"Lable\"]\n",
    "print('Shape of X = ', X.shape)\n",
    "print('Shape of y = ', y.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "id": "700d120d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Shape of X_train =  (8384, 6)\n",
      "Shape of y_train =  (8384,)\n",
      "Shape of X_test =  (2096, 6)\n",
      "Shape of y_test =  (2096,)\n"
     ]
    }
   ],
   "source": [
    "X_train, X_test, y_train, y_test =train_test_split(X, y, test_size=0.2, random_state=51)\n",
    "print('Shape of X_train = ', X_train.shape)\n",
    "print('Shape of y_train = ', y_train.shape)\n",
    "print('Shape of X_test = ', X_test.shape)\n",
    "print('Shape of y_test = ', y_test.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "id": "e34a22c3",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "sc = StandardScaler()\n",
    "sc.fit(X_train)\n",
    "X_train_sc = sc.transform(X_train)\n",
    "X_test_sc = sc.transform(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aa738417",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "id": "b8294e78",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy :  99.42748091603053\n",
      "Report : \n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           1       1.00      0.99      0.99       464\n",
      "           2       0.99      1.00      0.99       437\n",
      "           3       1.00      0.99      0.99       475\n",
      "           4       1.00      1.00      1.00       546\n",
      "           5       0.99      1.00      0.99       174\n",
      "\n",
      "    accuracy                           0.99      2096\n",
      "   macro avg       0.99      0.99      0.99      2096\n",
      "weighted avg       0.99      0.99      0.99      2096\n",
      "\n",
      "F1 Score :  99.41018474587604\n"
     ]
    }
   ],
   "source": [
    "#DECISION TREE\n",
    "from sklearn import tree\n",
    "import pickle\n",
    "dcf = tree.DecisionTreeClassifier()\n",
    "dcf = dcf.fit(X_train, y_train)\n",
    "\n",
    "p=dcf.predict(X_test)\n",
    "pickle.dump(dcf, open(\"dcf.pkl\", \"wb\"))\n",
    "dcf.score(X_test,y_test)\n",
    "\n",
    "from sklearn.metrics import confusion_matrix\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.metrics import f1_score\n",
    "from sklearn.metrics import classification_report \n",
    "print (\"Accuracy : \" , accuracy_score(y_test,p)*100)  \n",
    "print(\"Report : \\n\", classification_report(y_test, p))\n",
    "print(\"F1 Score : \",f1_score(y_test, p, average='macro')*100)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "id": "2a3b06ed",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "99.33206106870229\n",
      "Accuracy :  99.33206106870229\n",
      "Report : \n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           1       1.00      0.98      0.99       464\n",
      "           2       0.98      1.00      0.99       437\n",
      "           3       1.00      0.99      0.99       475\n",
      "           4       1.00      1.00      1.00       546\n",
      "           5       1.00      1.00      1.00       174\n",
      "\n",
      "    accuracy                           0.99      2096\n",
      "   macro avg       0.99      0.99      0.99      2096\n",
      "weighted avg       0.99      0.99      0.99      2096\n",
      "\n",
      "F1 Score :  99.38494624325301\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# # KNN MODEL\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "knn=KNeighborsClassifier(n_neighbors=3)\n",
    "knn.fit(X_train,y_train)\n",
    "\n",
    "pickle.dump(knn, open(\"KNN.pkl\", \"wb\"))\n",
    "pred=knn.predict(X_test)\n",
    "print(knn.score(X_test,y_test)*100)\n",
    "\n",
    "\n",
    "\n",
    "print (\"Accuracy : \" , accuracy_score(y_test,pred)*100)  \n",
    "print(\"Report : \\n\", classification_report(y_test, pred))\n",
    "print(\"F1 Score : \",f1_score(y_test, pred, average='macro')*100)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "id": "2e5c3873",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "78.91221374045801\n",
      "78.91221374045801\n",
      "78.91221374045801\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           1       0.59      0.97      0.74       464\n",
      "           2       0.57      0.12      0.19       437\n",
      "           3       0.84      0.97      0.90       475\n",
      "           4       1.00      0.95      0.97       546\n",
      "           5       1.00      1.00      1.00       174\n",
      "\n",
      "    accuracy                           0.79      2096\n",
      "   macro avg       0.80      0.80      0.76      2096\n",
      "weighted avg       0.78      0.79      0.74      2096\n",
      "\n",
      "F1 Score :  75.98140451552513\n"
     ]
    }
   ],
   "source": [
    "# # NAIVE BAYES MODEL\n",
    "# \n",
    "from sklearn.naive_bayes import GaussianNB\n",
    "gnb = GaussianNB()\n",
    "gnb.fit(X_train, y_train)\n",
    "\n",
    "pickle.dump(gnb, open(\"NAIVEBAYES.pkl\", \"wb\"))\n",
    "y_pred = gnb.predict(X_test)\n",
    "\n",
    "print(gnb.score(X_test,y_test)*100)\n",
    "from sklearn import metrics\n",
    "cm = metrics.confusion_matrix(y_test, y_pred)\n",
    "cm\n",
    "\n",
    "from sklearn.metrics import precision_score, recall_score\n",
    "\n",
    "print(precision_score(y_test, y_pred,average='micro')*100)\n",
    "print(recall_score(y_test, y_pred,average='micro')*100)\n",
    "from sklearn.metrics import classification_report\n",
    "print(classification_report(y_test,gnb.predict(X_test)))\n",
    "print(\"F1 Score : \",f1_score(y_test, y_pred, average='macro')*100)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "id": "da41d702",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "73.13931297709924\n",
      "73.13931297709924\n",
      "73.13931297709924\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           1       0.51      0.66      0.57       464\n",
      "           2       0.60      0.56      0.58       437\n",
      "           3       0.84      0.95      0.89       475\n",
      "           4       0.98      0.98      0.98       546\n",
      "           5       0.00      0.00      0.00       174\n",
      "\n",
      "    accuracy                           0.73      2096\n",
      "   macro avg       0.59      0.63      0.60      2096\n",
      "weighted avg       0.68      0.73      0.70      2096\n",
      "\n",
      "F1 Score :  60.443603868287134\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "D:\\jyputer\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:763: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n"
     ]
    }
   ],
   "source": [
    "# # LOGISTIC REGRESSION MODEL\n",
    "\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "# https://www.geeksforgeeks.org/implementation-of-logistic-regression-from-scratch-using-python/\n",
    "model = LogisticRegression()\n",
    "model.fit( X_train, y_train )  \n",
    "\n",
    "pickle.dump(model, open(\"LOGISTIC_REGRESSION.pkl\", \"wb\"))\n",
    "y1_pred = model.predict(X_test)\n",
    "print(model.score(X_test,y_test)*100)\n",
    "from sklearn import metrics\n",
    "cm = metrics.confusion_matrix(y_test,y1_pred )\n",
    "cm\n",
    "from sklearn.metrics import precision_score, recall_score\n",
    "\n",
    "print(precision_score(y_test, y1_pred,average='micro')*100)\n",
    "print(recall_score(y_test, y1_pred,average='micro')*100)\n",
    "from sklearn.metrics import classification_report\n",
    "print(classification_report(y_test,model.predict(X_test)))\n",
    "print(\"F1 Score : \",f1_score(y_test, y1_pred, average='macro')*100)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "id": "608ada3e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "67.31870229007633\n",
      "67.31870229007633\n",
      "67.31870229007633\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           1       0.42      0.75      0.54       464\n",
      "           2       0.38      0.16      0.23       437\n",
      "           3       0.84      0.98      0.90       475\n",
      "           4       1.00      0.96      0.98       546\n",
      "           5       0.00      0.00      0.00       174\n",
      "\n",
      "    accuracy                           0.67      2096\n",
      "   macro avg       0.53      0.57      0.53      2096\n",
      "weighted avg       0.62      0.67      0.63      2096\n",
      "\n",
      "F1 Score :  53.0803608498404\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "D:\\jyputer\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1248: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "D:\\jyputer\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1248: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "D:\\jyputer\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1248: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    }
   ],
   "source": [
    "# # SGDC CLASSIFER\n",
    "\n",
    "from sklearn.linear_model import SGDClassifier\n",
    "clf = SGDClassifier()\n",
    "clf.fit(X_train, y_train)\n",
    "pickle.dump(clf, open(\"SGD.pkl\", \"wb\"))\n",
    "\n",
    "y2_pred = clf.predict(X_test)\n",
    "\n",
    "print(clf.score(X_test,y_test)*100)\n",
    "\n",
    "from sklearn import metrics\n",
    "cm = metrics.confusion_matrix(y_test,y2_pred )\n",
    "cm\n",
    "\n",
    "from sklearn.metrics import precision_score, recall_score\n",
    "\n",
    "print(precision_score(y_test, y2_pred,average='micro')*100)\n",
    "print(recall_score(y_test, y2_pred,average='micro')*100)\n",
    "\n",
    "from sklearn.metrics import classification_report\n",
    "print(classification_report(y_test,clf.predict(X_test)))\n",
    "\n",
    "print(\"F1 Score : \",f1_score(y_test, y2_pred, average='macro')*100)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "id": "4ecf6a38",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "77.62404580152672\n",
      "77.62404580152672\n",
      "77.62404580152672\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           1       0.58      0.66      0.62       464\n",
      "           2       0.66      0.73      0.69       437\n",
      "           3       0.84      0.97      0.91       475\n",
      "           4       1.00      0.99      0.99       546\n",
      "           5       0.00      0.00      0.00       174\n",
      "\n",
      "    accuracy                           0.78      2096\n",
      "   macro avg       0.62      0.67      0.64      2096\n",
      "weighted avg       0.72      0.78      0.75      2096\n",
      "\n",
      "F1 Score :  64.17474213966217\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "D:\\jyputer\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1248: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "D:\\jyputer\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1248: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "D:\\jyputer\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1248: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    }
   ],
   "source": [
    "# # SVM CLASSIFER\n",
    "\n",
    "from sklearn import svm\n",
    "clff = svm.SVC(kernel='linear') \n",
    "clff.fit(X_train, y_train)\n",
    "y3_pred = clff.predict(X_test)\n",
    "\n",
    "pickle.dump(clff, open(\"SVM.pkl\", \"wb\"))\n",
    "\n",
    "print(clff.score(X_test,y_test)*100)\n",
    "\n",
    "from sklearn import metrics\n",
    "cm = metrics.confusion_matrix(y_test,y3_pred )\n",
    "cm\n",
    "\n",
    "from sklearn.metrics import precision_score, recall_score\n",
    "\n",
    "print(precision_score(y_test, y3_pred,average='micro')*100)\n",
    "print(recall_score(y_test, y3_pred,average='micro')*100)\n",
    "\n",
    "from sklearn.metrics import classification_report\n",
    "print(classification_report(y_test,clff.predict(X_test)))\n",
    "\n",
    "print(\"F1 Score : \",f1_score(y_test, y3_pred, average='macro')*100)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "id": "5d40c551",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "99.76145038167938\n",
      "77.62404580152672\n",
      "77.62404580152672\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           1       1.00      0.99      1.00       464\n",
      "           2       0.99      1.00      1.00       437\n",
      "           3       1.00      1.00      1.00       475\n",
      "           4       1.00      1.00      1.00       546\n",
      "           5       1.00      1.00      1.00       174\n",
      "\n",
      "    accuracy                           1.00      2096\n",
      "   macro avg       1.00      1.00      1.00      2096\n",
      "weighted avg       1.00      1.00      1.00      2096\n",
      "\n",
      "F1 Score :  64.17474213966217\n"
     ]
    }
   ],
   "source": [
    "# # RANDOM FOREST\n",
    "\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "\n",
    "#Create a Gaussian Classifier\n",
    "rf=RandomForestClassifier(n_estimators=100)\n",
    "#Train the model using the training sets y_pred=clf.predict(X_test)\n",
    "rf.fit(X_train, y_train)\n",
    "pickle.dump(clff, open(\"random forest.pkl\", \"wb\"))\n",
    "y4_pred = clff.predict(X_test)\n",
    "print(rf.score(X_test,y_test)*100)\n",
    "\n",
    "from sklearn import metrics\n",
    "cm = metrics.confusion_matrix(y_test,y4_pred )\n",
    "cm\n",
    "\n",
    "from sklearn.metrics import precision_score, recall_score\n",
    "\n",
    "print(precision_score(y_test, y4_pred,average='micro')*100)\n",
    "print(recall_score(y_test, y4_pred,average='micro')*100)\n",
    "\n",
    "from sklearn.metrics import classification_report\n",
    "print(classification_report(y_test,rf.predict(X_test)))\n",
    "\n",
    "print(\"F1 Score : \",f1_score(y_test, y4_pred, average='macro')*100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "id": "4f855c3a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "72.37595419847328\n",
      "72.37595419847328\n",
      "72.37595419847328\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           1       0.53      0.53      0.53       464\n",
      "           2       0.57      0.76      0.65       437\n",
      "           3       0.81      0.98      0.88       475\n",
      "           4       0.99      0.87      0.93       546\n",
      "           5       0.00      0.00      0.00       174\n",
      "\n",
      "    accuracy                           0.72      2096\n",
      "   macro avg       0.58      0.63      0.60      2096\n",
      "weighted avg       0.68      0.72      0.70      2096\n",
      "\n",
      "F1 Score :  59.886660055743825\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "D:\\jyputer\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1248: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "D:\\jyputer\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1248: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "D:\\jyputer\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1248: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# # ADABOOST\n",
    "\n",
    "from sklearn.ensemble import AdaBoostClassifier\n",
    "abc = AdaBoostClassifier(n_estimators=50,learning_rate=1)\n",
    "modell1 = abc.fit(X_train, y_train)\n",
    "pickle.dump(modell1, open(\"ADABOOST.pkl\", \"wb\"))\n",
    "y5_pred = modell1.predict(X_test)\n",
    "\n",
    "print(abc.score(X_test,y_test)*100)\n",
    "\n",
    "from sklearn import metrics\n",
    "cm = metrics.confusion_matrix(y_test,y5_pred )\n",
    "cm\n",
    "\n",
    "from sklearn.metrics import precision_score, recall_score\n",
    "\n",
    "print(precision_score(y_test, y5_pred,average='micro')*100)\n",
    "print(recall_score(y_test, y5_pred,average='micro')*100)\n",
    "\n",
    "from sklearn.metrics import classification_report\n",
    "print(classification_report(y_test,abc.predict(X_test)))\n",
    "print(\"F1 Score : \",f1_score(y_test, y5_pred, average='macro')*100)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "897bb7fd",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "d54dbabd",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "23782924",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "01aaa3c6",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8f5c109d",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "31f2aee4e71d21fbe5cf8b01ff0e069b9275f58929596ceb00d14d90e3e16cd6"
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
